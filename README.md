# Ngram-model

This is a project for COMS W4705 Natural Language Processingg at Columbia Univeristy. <br />
**The main task is to predict the word in a given context, using Baysean statistics.** The model was testedd using the Brown corpus, which is a sample of American written English collected in the 1950s, which is not shared here for copyright reasons. <br />
<br />
**The project contains 7 parts:** <br />
Part 1 - extracting n-grams from a sentence <br />
Part 2 - counting n-grams in a corpus <br />
Part 3 - Raw n-gram probabilities <br />
Part 4 - Smoothed probabilities <br />
Part 5 - Computing Sentence Probability <br />
Part 6 - Perplexity <br />
Part 7 - Using the Model for Text Classification <br />
