# Ngram-model

This is a project for COMS W4705 Natural Language Processingg at Columbia Univeristy. 
The main task is to preduct the word in a given context, using Baysean statistics. The model was testedd using the Brown corpus, which is a sample of American written English collected in the 1950s, which is not shared here for copyright reasons. 
The project contains 7 parts: 
Part 1 - extracting n-grams from a sentence
Part 2 - counting n-grams in a corpus
Part 3 - Raw n-gram probabilities
Part 4 - Smoothed probabilities
Part 5 - Computing Sentence Probability
Part 6 - Perplexity
Part 7 - Using the Model for Text Classification
